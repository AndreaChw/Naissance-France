#code simplifié

library(readxl)
library(dplyr)
library(tidyr)
library(ggplot2)
library(writexl)

# Charger les données
cat("Chargement des données...")
data <- read_excel("//Users/mehdifehri/Desktop/R/Données/Data R Ajustée.xlsx") %>%
  rename_with(~ gsub("-", "_", .), everything()) %>%
  select(-fem, -sco_jeune, -pop, -parc_logement, -viedans5, -acceuilenf, -agemat,)

cat("Les colonnes spécifiées ont été supprimées avec succès.\n")

##############################################################
# VISUALISATION DES TENDANCES
##############################################################

# Identifier les colonnes numériques (hors 'Temps' et 'fec')
numeric_cols <- setdiff(colnames(data), c("Temps", "fec"))

# Créer des graphiques de tendance pour chaque variable explicative
for (col in numeric_cols) {
  print(
    ggplot(data, aes_string(x = "Temps", y = col)) +
      geom_line(color = "blue") +
      labs(title = paste("Tendance de la variable", col), x = "Temps", y = col) +
      theme_minimal()
  )
}


##############################################################
# INTERPOLATION TRIMESTRIELLE ET DÉCALAGE TEMPOREL
##############################################################

# Identifier les colonnes numériques (hors 'Temps')
numeric_cols <- setdiff(colnames(data), "Temps")

# Interpolation trimestrielle et création des variables décalées (lags)
data_clean <- data %>%
  complete(Temps = seq(min(Temps), max(Temps), by = 0.25)) %>%
  mutate(across(all_of(numeric_cols),
                ~ approx(Temps[!is.na(.)], .[!is.na(.)], xout = Temps)$y)) %>%
  arrange(Temps) %>%
  mutate(across(setdiff(numeric_cols, "fec"), ~ lag(., n = 4), .names = "lag_{col}")) %>%
  drop_na(starts_with("lag_"))

# Sélectionner uniquement les colonnes nécessaires pour le modèle
data_work <- data_clean %>%
  select(Temps, fec, starts_with("lag_"))

# Sauvegarder le DataFrame intermédiaire
write_xlsx(data_work, "//Users/mehdifehri/Desktop/R/Data_Work.xlsx")
cat("Le fichier 'Data_Work.xlsx' a été sauvegardé après l'interpolation et le lag.\n")

rm(data)
rm(data_clean)

##############################################################
# CRÉATION DES MODÈLES AUXILIAIRES
##############################################################

cat("\n### Création des modèles auxiliaires ###\n")


# 1. Modèle standardisé (centré et réduit)
data_model_standardized <- data_work %>%
  mutate(across(starts_with("lag_"), ~ scale(.)))

##############################################################
# RÉGRESSION INITIALE SUR LE MODÈLE STANDARDISÉ
##############################################################

cat("\n### Régression initiale sur le modèle standardisé ###\n")

# Modèle OLS sur le modèle standardisé
model_standardized <- lm(fec ~ . - Temps, data = data_model_standardized)
print(summary(model_standardized))

##############################################################
# CALCUL DES R² POUR LE MODÈLE STANDARDISÉ
##############################################################

cat("\n### Calcul des R² pour le modèle standardisé ###\n")

# Calculer le \(R^2\) pour chaque variable explicative du modèle standardisé
r2_standardized <- data_model_standardized %>%
  summarise(across(starts_with("lag_"), 
                   ~ summary(lm(data_model_standardized$fec ~ .))$r.squared, 
                   .names = "R2_{col}")) %>%
  pivot_longer(cols = everything(), 
               names_to = "Variable", 
               values_to = "R2") %>%
  mutate(Variable = gsub("^R2_", "", Variable)) %>%
  arrange(desc(R2))

# Afficher et sauvegarder les résultats des \(R^2\)
print(r2_standardized)
write_xlsx(r2_standardized, "//Users/mehdifehri/Desktop/R/R2_Standardized_Results.xlsx")


##############################################################
# FILTRAGE DES VARIABLES BASÉ SUR LES R²
##############################################################

cat("\n### Filtrage des variables avec R² < 35% ###\n")

# Identifier les variables à conserver (R² >= 0.35)
variables_to_keep <- r2_standardized %>%
  filter(R2 >= 0.35) %>%
  pull(Variable)

# Identifier les variables supprimées (R² < 0.35)
variables_removed <- r2_standardized %>%
  filter(R2 < 0.35)

# Mettre à jour le DataFrame standardisé en supprimant les variables avec \(R^2 < 0.35\)
data_work1 <- data_model_standardized %>%
  select(all_of(c("fec", "Temps", variables_to_keep)))

# Afficher et sauvegarder les variables supprimées
print(variables_removed)
write_xlsx(variables_removed, "//Users/mehdifehri/Desktop/R/Variables_Removed_R2.xlsx")
cat("Le tableau des variables supprimées a été sauvegardé sous 'Variables_Removed_R2.xlsx'.\n")

##############################################################
# SAUVEGARDE DU NOUVEAU DATAFRAME
##############################################################

# Sauvegarder le DataFrame mis à jour
write_xlsx(data_work1, "//Users/mehdifehri/Desktop/R/Data_Work1_Standardized.xlsx")
cat("Le DataFrame mis à jour a été sauvegardé sous 'Data_Work1_Standardized.xlsx'.\n")

rm(data_model_standardized)
rm(data_work)
rm(r2_standardized)
rm(variables_removed)

##############################################################
# DÉTECTION ET TRAITEMENT DES OUTLIERS SUR LE MODÈLE STANDARDISÉ
##############################################################

cat("\n### Détection et traitement des outliers sur le modèle standardisé ###\n")

# Étape 1 : Ajuster le modèle global sur `data_work1`
model_standardized <- lm(fec ~ ., data = data_work1 %>% select(-Temps))

# Étape 2 : Calculer les résidus bruts et standardisés
residuals_standardized_df <- data.frame(
  Index = seq_len(nrow(data_work1)),
  Resid = residuals(model_standardized),      # Résidus bruts
  Std_Resid = rstandard(model_standardized),  # Résidus standardisés
  Temps = data_work1$Temps,
  fec = data_work1$fec
)

# Étape 3 : Visualiser les résidus bruts
plot_residus_bruts <- ggplot(residuals_standardized_df, aes(x = Index, y = Resid)) +
  geom_point(color = "darkorange") +
  geom_hline(yintercept = 0, color = "blue", linetype = "dashed") +
  labs(
    title = "Résidus Bruts (Modèle Standardisé)",
    x = "Index d'observation",
    y = "Résidus bruts"
  ) +
  theme_minimal()

print(plot_residus_bruts)

# Étape 4 : Visualiser les résidus standardisés (zoomé sur ±3)
threshold_zoom <- 3
plot_residus_standardises <- ggplot(residuals_standardized_df %>% filter(abs(Std_Resid) <= threshold_zoom)) +
  geom_point(aes(x = Index, y = Std_Resid), color = "blue") +
  geom_hline(yintercept = c(-1, 1), color = "red", linetype = "dashed") +
  labs(
    title = "Résidus Standardisés (Zoomé)",
    x = "Index d'observation",
    y = "Résidus standardisés"
  ) +
  theme_minimal()

print(plot_residus_standardises)

# Étape 5 : Identifier les outliers
threshold <- 1.5  # Seuil pour identifier les outliers
outliers_standardized_df <- residuals_standardized_df %>%
  filter(abs(Std_Resid) > threshold)

cat("\n### Résumé des outliers identifiés ###\n")
print(outliers_standardized_df)

# Étape 6 : Créer un nouveau DataFrame sans les outliers (`data_work2`)
data_work2 <- data_work1 %>%
  mutate(Index = seq_len(nrow(data_work1))) %>%
  filter(!Index %in% outliers_standardized_df$Index) %>%
  select(-Index)

# Étape 7 : Tableau récapitulatif des outliers
recap_outliers <- outliers_standardized_df %>%
  select(Temps, fec, Std_Resid)

# Sauvegarder les résultats finaux
write_xlsx(data_work2, "//Users/mehdifehri/Desktop/R/Data_Work2.xlsx")
write_xlsx(recap_outliers, "//Users/mehdifehri/Desktop/R/Recap_Outliers.xlsx")


rm(data_work1)
rm(recap_outliers)
rm(model_standardized)
rm(outliers_standardized_df)
rm(residuals_standardized_df)

##############################################################
# PARTIE 2 : DÉTECTION DES ALIAS (COLINÉARITÉ PARFAITE)
##############################################################


cat("\n### Détection des alias (colinéarité parfaite) ###\n")

# Étape 1 : Ajuster le modèle global pour `data_work2`
model_alias <- lm(fec ~ ., data = data_work2 %>% select(-Temps))

# Étape 2 : Utiliser le modèle global pour identifier les alias
alias_info <- alias(model_alias)

# Étape 3 : Extraire les colinéarités parfaites
alias_matrix <- alias_info$Complete  # Matrice de colinéarités parfaites

# Vérifier si des alias existent
if (is.null(alias_matrix)) {
  cat("Aucune colinéarité parfaite détectée dans le modèle.\n")
} else {
  # Étape 4 : Identifier les variables colinéaires
  alias_pairs <- which(alias_matrix != 0, arr.ind = TRUE)
  
  # Extraire les noms des variables impliquées dans les colinéarités
  alias_summary <- data.frame(
    Variable_1 = rownames(alias_matrix)[alias_pairs[, 1]],
    Variable_2 = colnames(alias_matrix)[alias_pairs[, 2]]
  ) %>%
    distinct()
  
  # Afficher la liste des colinéarités parfaites
  cat("Colinéarités parfaites détectées :\n")
  print(alias_summary)
  
  # Étape 5 : Sauvegarder les colinéarités dans un fichier Excel
  write_xlsx(alias_summary, "//Users/mehdifehri/Desktop/R/Colinear_Variables_Data_Work2.xlsx")
  cat("La liste des colinéarités parfaites a été sauvegardée dans 'Colinear_Variables_Data_Work2.xlsx'.\n")
}

# Étape 6 : Extraire les variables concernées par les alias
alias_vars <- rownames(alias_info$Complete)
cat("Variables impliquées dans les alias avec l'intercept :\n")
print(alias_vars)

# Étape 7 : Supprimer les variables alias et créer un nouveau DataFrame `data_work3`
data_work3 <- data_work2 %>%
  select(-all_of(alias_vars))

# Étape 8 : Sauvegarder le DataFrame mis à jour
write_xlsx(data_work3, "//Users/mehdifehri/Desktop/R/Data_Work3.xlsx")
cat("Le nouveau DataFrame sans alias a été sauvegardé sous 'Data_Work3.xlsx'.\n")

# Étape 9 : Résumer les variables supprimées
removed_variables_summary <- data.frame(Variables_Supprimées = alias_vars)
write_xlsx(removed_variables_summary, "//Users/mehdifehri/Desktop/R/Removed_Variables_Alias.xlsx")
cat("Résumé des variables supprimées enregistré sous 'Removed_Variables_Alias.xlsx'.\n")

rm(data_work2)
rm(alias_info)
rm(model_alias)
rm(removed_variables_summary)

##############################################################
# PARTIE 3 : ANALYSE DES VARIABLES EXPLICATIVES (CORRÉLATION, MDS, etc.)
##############################################################

library(dplyr)
library(tidyr)
library(writexl)
library(ggplot2)
library(reshape2)
library(stats)
library(igraph)

cat("\n### Analyse des variables explicatives (data_work3) ###\n")

# Charger le DataFrame `data_work3` directement
data_expl <- data_work3 %>%
  select(-Temps, -fec)  # Exclure les colonnes non explicatives

# Calculer la matrice de corrélation
cor_mat <- cor(data_expl, use = "complete.obs")
write_xlsx(as.data.frame(cor_mat), "//Users/mehdifehri/Desktop/R/Données/Correlation_Matrix_Data_Work3.xlsx")

cat("Matrice de corrélation (sans variable dépendante) :\n")
print(cor_mat)

# Heatmap
correlation_melted <- melt(cor_mat)
heatmap_plot <- ggplot(correlation_melted, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0,
                       limit = c(-1, 1), space = "Lab", name = "Corrélation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  labs(title = "Matrice de corrélation (data_work3)", x = "Variables", y = "Variables")

print(heatmap_plot)
ggsave("//Users/mehdifehri/Desktop/R/Données/Correlation_Heatmap_Data_Work3.png", plot = heatmap_plot,
       width = 10, height = 8, dpi = 300)

cat("Matrice de corrélation affichée, sauvegardée en Excel et heatmap PNG.\n")

# Identification des paires de variables fortement corrélées
corr_threshold <- 0.7
high_corr_pairs <- correlation_melted %>%
  filter(value > corr_threshold & Var1 != Var2) %>%
  arrange(desc(value)) %>%
  mutate(pair = paste0(pmin(as.character(Var1), as.character(Var2)), "-", pmax(as.character(Var1), as.character(Var2)))) %>%
  distinct(pair, .keep_all = TRUE) %>%
  select(-pair)

cat("Paires de variables avec corrélation >", corr_threshold, ":\n")
print(high_corr_pairs)
write_xlsx(high_corr_pairs, "//Users/mehdifehri/Desktop/R/Données/High_Correlation_Pairs_Data_Work3.xlsx")

# Compter les variables les plus fréquentes dans les paires corrélées
variable_counts <- high_corr_pairs %>%
  select(Var1, Var2) %>%
  pivot_longer(cols = everything(), values_to = "Variable") %>%
  group_by(Variable) %>%
  summarise(Frequency = n()) %>%
  arrange(desc(Frequency))

cat("\n### Variables les plus corrélées ###\n")
print(variable_counts)


##############################################################
# 4. VISUALISATION DE LA STRUCTURE DES VARIABLES (DENDRO, MDS, RÉSEAU)
##############################################################

cat("\n### Visualisation des structures des variables ###\n")

# Création d'une matrice de distance basée sur 1 - |corr|
dist_mat <- as.dist(1 - abs(cor_mat))

### Dendrogramme
hc <- hclust(dist_mat, method = "complete")
pdf("//Users/mehdifehri/Desktop/R/Données/Dendrogramme_Data_Work3.pdf", width = 10, height = 8)
plot(hc, main = "Dendrogramme des variables (data_work3)", xlab = "Variables", sub = "")
abline(h = 0.2, col = "red", lty = 2)  # Ajuster le seuil si nécessaire
dev.off()
cat("Dendrogramme sauvegardé en PDF.\n")

### MDS (Multi-Dimensional Scaling)
mds_res <- cmdscale(dist_mat, k = 2)
mds_df <- data.frame(
  Dim1 = mds_res[,1],
  Dim2 = mds_res[,2],
  Variable = rownames(mds_res)
)

mds_plot <- ggplot(mds_df, aes(x = Dim1, y = Dim2, label = Variable)) +
  geom_point() +
  geom_text(vjust = -0.5, size = 3) +
  labs(title = "Représentation MDS des variables (data_work3)", x = "Dimension 1", y = "Dimension 2") +
  theme_minimal()

print(mds_plot)
ggsave("//Users/mehdifehri/Desktop/R/Données/MDS_Plot_Data_Work3.pdf", plot = mds_plot, width = 10, height = 8)
cat("MDS plot affiché et sauvegardé en PDF.\n")

### Graphe de réseau
high_corr <- melt(cor_mat) %>%
  filter(value > corr_threshold & Var1 != Var2) %>%
  mutate(pair = paste(pmin(as.character(Var1), as.character(Var2)),
                      pmax(as.character(Var1), as.character(Var2)), sep = "-")) %>%
  distinct(pair, .keep_all = TRUE) %>%
  select(-pair)

g <- graph_from_data_frame(high_corr[, c("Var1", "Var2")], directed = FALSE)

plot(g,
     layout = layout_with_fr(g),
     vertex.size = 5,
     vertex.label.cex = 0.7,
     main = paste("Graphe de réseau des variables (corr >", corr_threshold, ")"))
cat("Graphe de réseau affiché.\n")

rm(g)
rm(hc)
rm(high_corr)
rm(high_corr_pairs)
rm(mds_df)
rm(mds_res)
rm(variable_counts)
rm(data_expl)
rm(cor_mat)
rm(correlation_melted)

#####################################################################
# Test VIF et suppression des variables avec VIF élevé (standardisation incluse)
#####################################################################


# Charger les bibliothèques nécessaires
library(car)  # Pour le calcul du VIF
library(dplyr)
library(writexl)

cat("\n### Début de la détection des VIF élevés dans data_work3 ###\n")

# Identifier les variables explicatives
variables_explicatives <- setdiff(names(data_work3), c("fec", "Temps"))

# Créer une copie des données pour le processus VIF
data_for_vif <- data_work3

# Définir le seuil de VIF
vif_threshold <- 30

# Initialiser les listes pour stocker les résultats
iteration_results <- list()
removed_variables <- data.frame(Iteration = integer(), Variable = character(), VIF_Value = numeric(), stringsAsFactors = FALSE)

# Boucle itérative pour supprimer les variables avec VIF élevé
iteration <- 1
while (TRUE) {
  cat("\n--- Itération", iteration, "---\n")
  
  # Ajuster un modèle linéaire avec les variables explicatives restantes
  current_model <- lm(fec ~ ., data = data_for_vif[, c("fec", variables_explicatives)])
  
  # Calculer le VIF pour chaque variable explicative
  vif_values <- vif(current_model)
  
  # Afficher les VIF actuels
  cat("Facteurs d'inflation de la variance (VIF) actuels :\n")
  print(vif_values)
  
  # Sauvegarder les résultats de l'itération
  iteration_results[[iteration]] <- data.frame(Variable = names(vif_values), VIF = vif_values, Iteration = iteration)
  
  # Identifier les variables avec un VIF supérieur au seuil
  high_vif_vars <- names(vif_values[vif_values > vif_threshold])
  
  # Vérifier s'il reste des variables avec un VIF élevé
  if (length(high_vif_vars) == 0) {
    cat("Toutes les variables ont un VIF <= ", vif_threshold, ". Fin de la boucle.\n")
    break
  }
  
  # Identifier la variable avec le VIF maximum
  variable_to_remove <- high_vif_vars[which.max(vif_values[high_vif_vars])]
  max_vif_value <- max(vif_values[high_vif_vars])
  cat("Variable avec le VIF le plus élevé :", variable_to_remove, "(", max_vif_value, ")\n")
  
  # Ajouter la variable supprimée à la liste des variables supprimées
  removed_variables <- rbind(removed_variables, data.frame(Iteration = iteration, Variable = variable_to_remove, VIF_Value = max_vif_value))
  
  # Supprimer cette variable des données et des variables explicatives
  data_for_vif <- data_for_vif %>% select(-all_of(variable_to_remove))
  variables_explicatives <- setdiff(variables_explicatives, variable_to_remove)
  
  # Augmenter le compteur d'itérations
  iteration <- iteration + 1
}

data_work4 <- data_for_vif

# Sauvegarder les données finales sans VIF élevé
write_xlsx(data_work4, "//Users/mehdifehri/Desktop/R/Données/Data_Work4.xlsx")
cat("Les données finales après suppression des variables avec VIF > ", vif_threshold, " ont été sauvegardées sous 'Data_Work4.xlsx'.\n")

# Sauvegarder les résultats des VIF à chaque itération
all_iterations_vif <- bind_rows(iteration_results)
cat("Les résultats des VIF pour chaque itération ont été sauvegardés sous 'Iterative_VIF_Results.xlsx'.\n")

# Sauvegarder les variables supprimées et leurs VIF
cat("Les variables supprimées et leurs VIF ont été sauvegardées sous 'Removed_Variables_VIF.xlsx'.\n")

# Imprimer les noms des colonnes du nouveau DataFrame `data_work4`
cat("\nNoms des colonnes du DataFrame `data_work4` :\n")
print(names(data_for_vif))

# Sauvegarder le DataFrame
write_xlsx(data_work4, "//Users/mehdifehri/Desktop/R/Données/Correlation_Matrix_Data_Work3.xlsx")
cat("Le fichier a été sauvegardé avec succès.\n")


rm(all_iterations_vif)
rm(current_model)
rm(data_work3)
rm(iteration_results)
rm(removed_variables)
rm(data_for_vif)


###################################################################
####### RÉGRESSION OLS DE BASE SUR MODÈLE STANDARDISÉE ###################################
###################################################################


library(lmtest)

# Modèle OLS de base sans la variable Temps
model_ols <- lm(fec ~ . - Temps, data = data_work4)
print(summary(model_ols))

# Test RESET pour le modèle OLS
cat("\n### Test RESET pour le modèle OLS ###\n")

# Effectuer le test RESET
reset_test_ols <- resettest(model_ols, power = 2:3, type = "fitted")

# Afficher les résultats du test RESET
print(reset_test_ols)

# Interprétation du test RESET
if (reset_test_ols$p.value > 0.05) {
  cat("\nInterprétation : Le modèle est correctement spécifié. (p-value =", reset_test_ols$p.value, ")\n")
} else {
  cat("\nInterprétation : Le modèle est mal spécifié. (p-value =", reset_test_ols$p.value, ")\n")
}

##############################################################
# CRÉATION RAPIDE DU DATAFRAME NON STANDARDISÉ
##############################################################

library(dplyr)

# Vérifier les attributs des colonnes
lapply(data_work4, attributes)


# Vérifier que les attributs "scaled:scale" et "scaled:center" existent dans data_work4
data_work_original <- data_work4 %>%
  mutate(across(
    -c(fec, Temps), 
    ~ . * attr(data_work4[[cur_column()]], "scaled:scale") + 
      attr(data_work4[[cur_column()]], "scaled:center")
  ))

cat("Les données non standardisées ont été recréées avec succès.\n")


# Sauvegarder le DataFrame non standardisé
write_xlsx(data_work_original, "//Users/mehdifehri/Desktop/R/Data_Work_Original.xlsx")
cat("Le DataFrame non standardisé avec des noms de colonnes corrigés a été sauvegardé sous 'Data_Work_Original.xlsx'.\n")

##############################################################
# CRÉATION DES MODÈLES
##############################################################


# Modèle excluant la variable Temps
model_original_no_temps <- lm(fec ~ . - Temps, data = data_work_original)

# Afficher le résumé du modèle sans Temps
cat("\n### Résumé du modèle excluant Temps ###\n")
print(summary(model_original_no_temps))

##############################################################
# TEST RESET P
##############################################################

# Charger la bibliothèque pour le test RESET
library(lmtest)

# Test RESET pour le modèle sans la variable Temps
cat("\n### Test RESET pour le modèle excluant Temps ###\n")
reset_test_without_temps <- resettest(model_original_no_temps, power = 2:3, type = "fitted")
print(reset_test_without_temps)

if (reset_test_without_temps$p.value > 0.05) {
  cat("\nInterprétation : Le modèle sans Temps est correctement spécifié.\n")
} else {
  cat("\nInterprétation : Le modèle sans Temps est mal spécifié.\n")
}

rm(reset_test_ols)
rem(reset_test_without_temps)

##############################################################
# TEST DE BOX-COX POUR LES MODÈLES INITIAUX
##############################################################

library(dplyr)
library(MASS)  # Pour le test Box-Cox

# Test Box-Cox pour le modèle sans Temps
cat("\n### Test de Box-Cox pour le modèle excluant Temps ###\n")
boxcox_without_temps <- boxcox(model_original_no_temps, lambda = seq(-2, 2, by = 0.1))
lambda_without_temps <- boxcox_without_temps$x[which.max(boxcox_without_temps$y)]
cat("Lambda optimal (modèle sans Temps) :", lambda_without_temps, "\n")


rm(boxcox_without_temps)
#############################################################
# CRÉATION DE MODÈLES AUXILIAIRES
##############################################################

# Modèle auxiliaire : log-log
data_work_loglog <- data_work_original %>%
  mutate(across(-c(fec, Temps), ~ log(. + 1)),
         fec = log(fec + 1))

# Modèle auxiliaire : log uniquement (variable dépendante)
data_work_log <- data_work_original %>%
  mutate(fec = log(fec + 1))

# Modèle auxiliaire : polynomial
data_work_poly <- data_work_original %>%
  mutate(across(-c(fec, Temps), ~ .^2, .names = "poly_{col}"))

# Modèle auxiliaire : log-log polynomial (log(y) - log(x)^2)
data_work_loglogpoly <- data_work_original %>%
  mutate(across(-c(fec, Temps), ~ log(. + 1)),
         fec = log(fec + 1),
         across(-c(fec, Temps), ~ .^2, .names = "poly_{col}"))

# Modèle auxiliaire : Box-Cox avec lambda = -2 (inverse carré)
data_work_boxcox <- data_work_original %>%
  mutate(fec = 1 / (fec^2))

##############################################################
# AJUSTEMENT DES MODÈLES AUXILIAIRES
##############################################################

# Modèles auxiliaires sans la variable Temps
model_loglog_no_temps <- lm(fec ~ . - Temps, data = data_work_loglog)
model_log_no_temps <- lm(fec ~ . - Temps, data = data_work_log)
model_poly_no_temps <- lm(fec ~ . - Temps, data = data_work_poly)
model_loglogpoly_no_temps <- lm(fec ~ . - Temps, data = data_work_loglogpoly)
model_boxcox_no_temps <- lm(fec ~ . - Temps, data = data_work_boxcox)

##############################################################
# TEST RESET POUR CHAQUE MODÈLE AUXILIAIRE
##############################################################

library(lmtest)  # Pour le test RESET

# Fonction pour effectuer un RESET test et interpréter les résultats
perform_reset <- function(model, model_name) {
  reset_test <- resettest(model, power = 2:3, type = "fitted")
  interpretation <- ifelse(reset_test$p.value > 0.05, "Le modèle est correctement spécifié", "Le modèle est mal spécifié")
  return(list(p_value = reset_test$p.value, interpretation = interpretation))
}

# Liste des modèles et leurs noms
models <- list(
  "Log-Log sans Temps" = model_loglog_no_temps,
  "Log sans Temps" = model_log_no_temps,
  "Polynomial sans Temps" = model_poly_no_temps,
  "Log-Log Polynomial sans Temps" = model_loglogpoly_no_temps,
  "Box-Cox (lambda = -2) sans Temps" = model_boxcox_no_temps
)

##############################################################
# TABLEAU COMPARATIF DES RÉSULTATS
##############################################################

# Initialisation du tableau récapitulatif
model_comparison <- data.frame(
  Model = character(),
  Adjusted_R2 = numeric(),
  AIC = numeric(),
  BIC = numeric(),
  RESET_p_value = numeric(),
  RESET_Interpretation = character(),
  stringsAsFactors = FALSE
)

# Remplir le tableau pour chaque modèle
for (name in names(models)) {
  model <- models[[name]]
  summary_model <- summary(model)
  reset_results <- perform_reset(model, name)
  
  model_comparison <- rbind(model_comparison, data.frame(
    Model = name,
    Adjusted_R2 = summary_model$adj.r.squared,
    AIC = AIC(model),
    BIC = BIC(model),
    RESET_p_value = reset_results$p_value,
    RESET_Interpretation = reset_results$interpretation
  ))
}

print(model_comparison)
# Sauvegarder le tableau récapitulatif
write_xlsx(model_comparison, "//Users/mehdifehri/Desktop/R/Model_Comparison_Results.xlsx")

cat("Le tableau comparatif des modèles a été sauvegardé sous 'Model_Comparison_Results.xlsx'.\n")


rm(data_work_boxcox)
rm(data_work_log)
rm(data_work_loglog)
rm(data_work_original)
rm(data_work_poly)
rm(data_work4)
rm(model)
rm(model_boxcox_no_temps)
rm(model_boxcox_with_temps)
rm(model_log_no_temps)
rm(model_log_with_temps)
rm(model_loglogpoly_with_temps)
rm(model_ols)
rm(model_original_no_temps)
rm(model_original_temps)
rm(models)
rm(model_loglog_no_temps)
rm(model_loglog_with_temps)
rm(model_poly_no_temps)
rm(model_poly_with_temps)
rm(reset_results)
rm(reset_test_without_temps)
rm(summary_model)


# Charger les bibliothèques nécessaires
library(broom)
library(writexl)
library(dplyr)
#############################################################
# RÉGRESSION OLS SUR LE MODÈLE FINAL (data_work_loglogpoly)
#############################################################

# Réaliser la régression OLS sans la variable Temps
cat("\n### Régression OLS sur le modèle final (sans Temps) ###\n")
model_final <- lm(fec ~ . - Temps, data = data_work_loglogpoly)


# Modèle final OLS
summary_model_final <- summary(model_final)
print(summary_model_final)

# Résidus du modèle final
residus <- residuals(model_final)

# Exclure Temps et fec des variables explicatives
explicatives <- model_final$model %>% 
  select(-fec, -Temps)

#############################################################
# Visualisations des résidus
#############################################################

cat("\n### Visualisations des résidus ###\n")

# Résidus vs valeurs ajustées
plot(fitted(model_final), residus, main = "Résidus vs valeurs ajustées",
     xlab = "Valeurs ajustées", ylab = "Résidus", pch = 19, col = "blue")
abline(h = 0, col = "red", lty = 2)

# Résidus vs indices
plot(1:length(residus), residus, main = "Résidus vs indices",
     xlab = "Indice", ylab = "Résidus", pch = 19, col = "green")
abline(h = 0, col = "red", lty = 2)

# Histogramme des résidus
hist(residus, breaks = 15, col = "gray", main = "Histogramme des résidus", xlab = "Résidus")

# QQ-Plot des résidus
qqnorm(residus, main = "Q-Q Plot des résidus")
qqline(residus, col = "red")

#############################################################
# Hypothèses de Gauss-Markov + 1
#############################################################

####################################################
# Étape 1 : Résidus de moyenne nulle
####################################################
cat("\n### Hypothèse 1 : Résidus de moyenne nulle ###\n")
mean_residuals <- mean(residus)
std_error_residuals <- sd(residus) / sqrt(length(residus))
t_stat <- mean_residuals / std_error_residuals
p_value <- 2 * pt(-abs(t_stat), df = length(residus) - 1)

cat("Résultats du test :\n")
cat(paste("Moyenne des résidus :", mean_residuals, "\n"))
cat(paste("t-statistic :", t_stat, "p-value :", p_value, "\n"))

if (p_value > 0.05) {
  cat("H₀ est vérifiée : les résidus ont une moyenne nulle.\n")
} else {
  cat("H₀ est rejetée : les résidus n'ont pas une moyenne nulle.\n")
}

#############################################################
# Étape 2 : Indépendance entre résidus et variables explicatives
#############################################################
cat("\n### Hypothèse 2 : Indépendance entre résidus et variables explicatives ###\n")
variables_explicatives <- names(model_final$model)[-1]  # Exclure la variable dépendante
results <- lapply(variables_explicatives, function(var) {
  corr_test <- cor.test(model_final$model[[var]], residus)
  data.frame(
    Variable = var,
    Correlation = corr_test$estimate,
    P_value = corr_test$p.value,
    Significant = corr_test$p.value <= 0.05
  )
}) %>% bind_rows()

cat("Résultats du test d'indépendance :\n")
print(results)

if (any(results$Significant)) {
  cat("Certaines variables explicatives sont corrélées aux résidus. L'hypothèse d'indépendance est rejetée.\n")
} else {
  cat("Aucune variable explicative n'est corrélée aux résidus. H₀ est vérifiée : indépendance respectée.\n")
}

##########################################################
# Étape 3 : Homoscédasticité (Tests de Breusch-Pagan et White)
##########################################################

# Test de Breusch-Pagan
cat("\n--- Test de Breusch-Pagan ---\n")
bp_model <- lm(residuals(model_final)^2 ~ ., data = explicatives)  # Modèle auxiliaire pour Breusch-Pagan
summary_bp_model <- summary(bp_model)

cat("\n--- Régression auxiliaire pour le test de Breusch-Pagan ---\n")
print(summary_bp_model)

test_bp <- bptest(model_final)  # Test de Breusch-Pagan
print(test_bp)

if (test_bp$p.value > 0.05) {
  cat("H₀ est vérifiée : les résidus ont une variance constante (homoscédasticité, Breusch-Pagan).\n")
} else {
  cat("H₀ est rejetée : les résidus n'ont pas une variance constante (hétéroscédasticité, Breusch-Pagan).\n")
}

# Test de White
cat("\n--- Test de White ---\n")
white_model <- lm(residuals(model_final)^2 ~ poly(fitted(model_final), 2), data = explicatives)  # Modèle auxiliaire pour White
summary_white_model <- summary(white_model)

cat("\n--- Régression auxiliaire pour le test de White ---\n")
print(summary_white_model)

white_stat <- summary_white_model$r.squared * nrow(model_final$model)  # Calcul de la statistique de White
white_pval <- pchisq(white_stat, df = 2, lower.tail = FALSE)  # Degré de liberté = 2 (termes quadratiques)

cat("Statistique du test de White :", white_stat, "\n")
cat("P-value du test de White :", white_pval, "\n")

if (white_pval > 0.05) {
  cat("H₀ est vérifiée : les résidus ont une variance constante (homoscédasticité, White).\n")
} else {
  cat("H₀ est rejetée : les résidus n'ont pas une variance constante (hétéroscédasticité, White).\n")
}

#######################################################
# Étape 4 : Tests pour l'absence d'autocorrélation
#######################################################

library(lmtest)
library(dplyr)
cat("\n### Hypothèse 4 : Absence d'autocorrélation ###\n")

# Test de Durbin-Watson
cat("\n--- Test de Durbin-Watson ---\n")
test_dw <- dwtest(model_final)
print(test_dw)

if (test_dw$p.value > 0.05) {
  cat("H₀ est vérifiée : il n'y a pas d'autocorrélation des résidus (Durbin-Watson).\n")
} else {
  cat("H₀ est rejetée : il existe une autocorrélation des résidus (Durbin-Watson).\n")
}

#######################################################
# Test de Breusch-Godfrey avec détails
#######################################################
cat("\n--- Test de Breusch-Godfrey avec détails ---\n")

# Calculer le test de Breusch-Godfrey
test_bg <- bgtest(model_final, order = 40)  # Spécifiez l'ordre souhaité
print(test_bg)

# Interprétation des résultats
if (test_bg$p.value > 0.05) {
  cat("H₀ est vérifiée : il n'y a pas d'autocorrélation des résidus (Breusch-Godfrey).\n")
} else {
  cat("H₀ est rejetée : il existe une autocorrélation des résidus (Breusch-Godfrey).\n")
}

#######################################################
# Régression auxiliaire pour le test de Breusch-Godfrey
#######################################################
cat("\n--- Régression auxiliaire pour le test de Breusch-Godfrey ---\n")

# Obtenir les résidus du modèle
residuals_model <- residuals(model_final)

# Créer un DataFrame auxiliaire avec les termes de lag pour les résidus
data_aux <- model_final$model %>%
  mutate(
    residuals = residuals_model,                 # Ajouter les résidus
    lag1 = dplyr::lag(residuals_model, 1),       # Lag de 1
    lag2 = dplyr::lag(residuals_model, 2)        # Lag de 2
  ) %>%
  na.omit()  # Supprimer les lignes avec NA dues aux lags

# Régression auxiliaire avec les termes de lag
aux_model_bg <- lm(residuals ~ lag1 + lag2 + ., data = data_aux)

# Afficher le résumé de la régression auxiliaire
print(summary(aux_model_bg))

cat("\nLa régression auxiliaire montre comment les résidus sont influencés par leurs lags et les variables explicatives du modèle principal.\n")

#######################################################
# Test de Ljung-Box avec détails sur l'autocorrélation
#######################################################

cat("\n--- Test de Ljung-Box avec visualisation ---\n")

# Étape 1 : Calcul des résidus du modèle final
residuals_final <- residuals(model_final)

# Étape 2 : Réalisation du test de Ljung-Box
lag_max <- 10  # Nombre maximum de lags à examiner
test_lb <- Box.test(residuals_final, lag = lag_max, type = "Ljung-Box")

cat("Résultats du test de Ljung-Box (lag =", lag_max, "):\n")
print(test_lb)

if (test_lb$p.value > 0.05) {
  cat("H₀ est vérifiée : il n'y a pas d'autocorrélation des résidus (Ljung-Box).\n")
} else {
  cat("H₀ est rejetée : il existe une autocorrélation des résidus (Ljung-Box).\n")
}

# Étape 3 : Analyse détaillée et visualisation

# 3.1. Calcul des autocorrélations (ACF) et autocorrélations partielles (PACF)
acf_res <- acf(residuals_final, plot = FALSE)
pacf_res <- pacf(residuals_final, plot = FALSE)

# 3.2. Visualisation de l'ACF
plot(acf_res, main = "Autocorrélation (ACF) des résidus", xlab = "Lags", ylab = "Autocorrélation")

# Pause pour visualiser l'ACF avant de passer à la PACF
cat("\nAppuyez sur [Entrée] pour afficher le graphique de la PACF...\n")
readline()

# 3.3. Visualisation de la PACF
plot(pacf_res, main = "Autocorrélation partielle (PACF) des résidus", xlab = "Lags", ylab = "Autocorrélation partielle")

# Étape 4 : Résumé détaillé des ACF
cat("\n--- Résumé des autocorrélations (ACF) ---\n")
acf_values <- acf_res$acf[2:(lag_max + 1)]  # Exclure le lag 0
lags <- 1:lag_max
acf_summary <- data.frame(Lag = lags, Autocorrelation = acf_values)

print(acf_summary)

# Étape 5 : Résumé des PACF
cat("\n--- Résumé des autocorrélations partielles (PACF) ---\n")
pacf_values <- pacf_res$acf[1:lag_max]  # Lags jusqu'à lag_max
pacf_summary <- data.frame(Lag = lags, Partial_Autocorrelation = pacf_values)

print(pacf_summary)

# Étape 6 : Enregistrer les résultats dans des fichiers Excel
library(writexl)

write_xlsx(acf_summary, "//Users/mehdifehri/Desktop/R/Données/ACF_Summary.xlsx")
write_xlsx(pacf_summary, "//Users/mehdifehri/Desktop/R/Données/PACF_Summary.xlsx")

cat("Les résumés des ACF et PACF ont été sauvegardés sous 'ACF_Summary.xlsx' et 'PACF_Summary.xlsx'.\n")

#####################################################
# Étape 5 : Normalité des résidus
#####################################################
# Vérification de la normalité des résidus avec les tests de Shapiro-Wilk et Anderson-Darling
cat("\n### Hypothèse 5 : Normalité des résidus ###\n")

library(nortest)

test_shapiro <- shapiro.test(residus)
ad_test <- ad.test(residus)

cat("Résultats du test de Shapiro-Wilk :\n")
print(test_shapiro)

cat("Résultats du test d'Anderson-Darling :\n")
print(ad_test)

if (test_shapiro$p.value > 0.05) {
  cat("H₀ est vérifiée : les résidus suivent une distribution normale (Shapiro-Wilk).\n")
} else {
  cat("H₀ est rejetée : les résidus ne suivent pas une distribution normale (Shapiro-Wilk).\n")
}

if (ad_test$p.value > 0.05) {
  cat("H₀ est vérifiée : les résidus suivent une distribution normale (Anderson-Darling).\n")
} else {
  cat("H₀ est rejetée : les résidus ne suivent pas une distribution normale (Anderson-Darling).\n")
}

#####################################################################################
################ DIAGNOSITQUE APPROFONDIE HETEROSCEDASTICITÉ #######################
#################################################################################


#####################################################################################
################ DIAGNOSITQUE APPROFONDIE AUTOCORRELATION #######################
#################################################################################
